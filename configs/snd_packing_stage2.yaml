# 模型相关配置
model_name_or_path: "/data/name_disambiguation/model/Alibaba-NLP/gte-Qwen2-7B-instruct"
padding_side: "left"
use_graph: true
use_lora: false
dynamic_weight: false
lora_module_path: "/data/name_disambiguation/model/7B-Qwen-1Pos-12Pack-0.05Temp-4e-06LR-Shuffled/checkpoint-1600/lora.safetensors"
graph_hidden_size: 512

# 数据相关配置
packing_size: 12
positive_num: 1
shuffle: true

graph_feature_path: "/data/name_disambiguation/WhoIsWho_his/bond/dataset/data/llm/embeddings-0.safetensors"

# 训练流程控制
do_predict: false
resume_from_checkpoint: "/data/name_disambiguation/model/SNDPacking/checkpoint-1"
num_train_epochs: 1
save_steps: 200
save_total_limit: 200
evaluation_strategy: "steps"
eval_steps: 200
load_best_model_at_end: false
metric_for_best_model: "avg_f1"
remove_unused_columns: false
use_cluster_loss: false

# 优化器相关
learning_rate: 0.00001
warmup_ratio: 0.1
lr_scheduler_type: "cosine"

# 聚类相关参数
db_min: 5
db_eps: 0.05

# 对比学习温度参数
temperature: 0.05
temperature_decay: 0.99
temperature_decay_step: 200

# 硬件/性能配置
per_device_train_batch_size: 1
per_device_eval_batch_size: 1
gradient_accumulation_steps: 1
bf16: true
deepspeed: "/data/name_disambiguation/configs/ds_configs/ds_zero_2.json"

# 日志和输出
output_dir: "/data/name_disambiguation/model"
report_to: "wandb"
logging_steps: 1