# 模型相关配置
model_name_or_path: "/data/name_disambiguation/model/Alibaba-NLP/gte-Qwen2-1.5B-instruct"
padding_side: "left"
use_graph: true
use_lora: false
lora_module_path: "/data/name_disambiguation/model/1.5B-Qwen-1Pos-24Pack-0.05Temp-8e-06LR-Shuffled-ClusterLoss-LossWeight2.0/checkpoint-1200/lora.safetensors"
enable_quantization: false
dynamic_weight: false
graph_hidden_size: 512
loss_weight: 2.0

# 数据相关配置
packing_size: 24
positive_num: 1
shuffle: false
graph_feature_path: "/data/name_disambiguation/data/SND/graph-features/7B-fixed/llm/embeddings-0.safetensors"

# 训练流程控制
do_predict: false
num_train_epochs: 1
save_steps: 200
save_total_limit: 200
evaluation_strategy: "steps"
eval_steps: 200
load_best_model_at_end: false
metric_for_best_model: "avg_f1"
remove_unused_columns: false
use_cluster_loss: true

# 优化器相关
learning_rate: 0.0000006
warmup_ratio: 0.1
lr_scheduler_type: "cosine"

# 聚类相关参数
db_min: 5
db_eps: 0.1

# 对比学习温度参数
temperature: 0.05
temperature_decay: 1
temperature_decay_step: 200

# 硬件/性能配置
per_device_train_batch_size: 1
per_device_eval_batch_size: 1
gradient_accumulation_steps: 1
bf16: true
deepspeed: "/data/name_disambiguation/configs/ds_configs/ds_zero_2.json"

# 日志和输出
output_dir: "/data/name_disambiguation/model"
report_to: "wandb"
logging_steps: 1